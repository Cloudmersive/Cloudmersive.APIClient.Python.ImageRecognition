# coding: utf-8

"""
    imageapi

    Image Recognition and Processing APIs let you use Artificial Intelligence and Machine Learning to recognize and process images, and also perform useful image modification operations.  # noqa: E501

    OpenAPI spec version: v1
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""


import pprint
import re  # noqa: F401

import six


class NsfwAdvancedResult(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """

    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'successful': 'bool',
        'clean_result': 'bool',
        'contains_nudity': 'bool',
        'contains_graphic_violence': 'bool',
        'contains_non_graphic_violence': 'bool',
        'contains_self_harm': 'bool',
        'contains_hate': 'bool',
        'contains_potential_illegal_activity': 'bool',
        'contains_medical_imagery': 'bool',
        'contains_profanity': 'bool',
        'score': 'float',
        'classification_outcome': 'str'
    }

    attribute_map = {
        'successful': 'Successful',
        'clean_result': 'CleanResult',
        'contains_nudity': 'ContainsNudity',
        'contains_graphic_violence': 'ContainsGraphicViolence',
        'contains_non_graphic_violence': 'ContainsNonGraphicViolence',
        'contains_self_harm': 'ContainsSelfHarm',
        'contains_hate': 'ContainsHate',
        'contains_potential_illegal_activity': 'ContainsPotentialIllegalActivity',
        'contains_medical_imagery': 'ContainsMedicalImagery',
        'contains_profanity': 'ContainsProfanity',
        'score': 'Score',
        'classification_outcome': 'ClassificationOutcome'
    }

    def __init__(self, successful=None, clean_result=None, contains_nudity=None, contains_graphic_violence=None, contains_non_graphic_violence=None, contains_self_harm=None, contains_hate=None, contains_potential_illegal_activity=None, contains_medical_imagery=None, contains_profanity=None, score=None, classification_outcome=None):  # noqa: E501
        """NsfwAdvancedResult - a model defined in Swagger"""  # noqa: E501

        self._successful = None
        self._clean_result = None
        self._contains_nudity = None
        self._contains_graphic_violence = None
        self._contains_non_graphic_violence = None
        self._contains_self_harm = None
        self._contains_hate = None
        self._contains_potential_illegal_activity = None
        self._contains_medical_imagery = None
        self._contains_profanity = None
        self._score = None
        self._classification_outcome = None
        self.discriminator = None

        if successful is not None:
            self.successful = successful
        if clean_result is not None:
            self.clean_result = clean_result
        if contains_nudity is not None:
            self.contains_nudity = contains_nudity
        if contains_graphic_violence is not None:
            self.contains_graphic_violence = contains_graphic_violence
        if contains_non_graphic_violence is not None:
            self.contains_non_graphic_violence = contains_non_graphic_violence
        if contains_self_harm is not None:
            self.contains_self_harm = contains_self_harm
        if contains_hate is not None:
            self.contains_hate = contains_hate
        if contains_potential_illegal_activity is not None:
            self.contains_potential_illegal_activity = contains_potential_illegal_activity
        if contains_medical_imagery is not None:
            self.contains_medical_imagery = contains_medical_imagery
        if contains_profanity is not None:
            self.contains_profanity = contains_profanity
        if score is not None:
            self.score = score
        if classification_outcome is not None:
            self.classification_outcome = classification_outcome

    @property
    def successful(self):
        """Gets the successful of this NsfwAdvancedResult.  # noqa: E501

        True if the classification was successfully run, false otherwise  # noqa: E501

        :return: The successful of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._successful

    @successful.setter
    def successful(self, successful):
        """Sets the successful of this NsfwAdvancedResult.

        True if the classification was successfully run, false otherwise  # noqa: E501

        :param successful: The successful of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._successful = successful

    @property
    def clean_result(self):
        """Gets the clean_result of this NsfwAdvancedResult.  # noqa: E501

        True if the result was clean, false otherwise  # noqa: E501

        :return: The clean_result of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._clean_result

    @clean_result.setter
    def clean_result(self, clean_result):
        """Sets the clean_result of this NsfwAdvancedResult.

        True if the result was clean, false otherwise  # noqa: E501

        :param clean_result: The clean_result of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._clean_result = clean_result

    @property
    def contains_nudity(self):
        """Gets the contains_nudity of this NsfwAdvancedResult.  # noqa: E501

        True if the image contains nudity or sex, false otherwise  # noqa: E501

        :return: The contains_nudity of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._contains_nudity

    @contains_nudity.setter
    def contains_nudity(self, contains_nudity):
        """Sets the contains_nudity of this NsfwAdvancedResult.

        True if the image contains nudity or sex, false otherwise  # noqa: E501

        :param contains_nudity: The contains_nudity of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._contains_nudity = contains_nudity

    @property
    def contains_graphic_violence(self):
        """Gets the contains_graphic_violence of this NsfwAdvancedResult.  # noqa: E501

        True if the image contains graphic violence and/or gore, false otherwise  # noqa: E501

        :return: The contains_graphic_violence of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._contains_graphic_violence

    @contains_graphic_violence.setter
    def contains_graphic_violence(self, contains_graphic_violence):
        """Sets the contains_graphic_violence of this NsfwAdvancedResult.

        True if the image contains graphic violence and/or gore, false otherwise  # noqa: E501

        :param contains_graphic_violence: The contains_graphic_violence of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._contains_graphic_violence = contains_graphic_violence

    @property
    def contains_non_graphic_violence(self):
        """Gets the contains_non_graphic_violence of this NsfwAdvancedResult.  # noqa: E501

        True if the image contains non-graphic violence, e.g. weapons, false otherwise  # noqa: E501

        :return: The contains_non_graphic_violence of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._contains_non_graphic_violence

    @contains_non_graphic_violence.setter
    def contains_non_graphic_violence(self, contains_non_graphic_violence):
        """Sets the contains_non_graphic_violence of this NsfwAdvancedResult.

        True if the image contains non-graphic violence, e.g. weapons, false otherwise  # noqa: E501

        :param contains_non_graphic_violence: The contains_non_graphic_violence of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._contains_non_graphic_violence = contains_non_graphic_violence

    @property
    def contains_self_harm(self):
        """Gets the contains_self_harm of this NsfwAdvancedResult.  # noqa: E501

        True if the image contains self-harm or suicide imagery, false otherwise  # noqa: E501

        :return: The contains_self_harm of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._contains_self_harm

    @contains_self_harm.setter
    def contains_self_harm(self, contains_self_harm):
        """Sets the contains_self_harm of this NsfwAdvancedResult.

        True if the image contains self-harm or suicide imagery, false otherwise  # noqa: E501

        :param contains_self_harm: The contains_self_harm of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._contains_self_harm = contains_self_harm

    @property
    def contains_hate(self):
        """Gets the contains_hate of this NsfwAdvancedResult.  # noqa: E501

        True if the image contains hate, false otherwise  # noqa: E501

        :return: The contains_hate of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._contains_hate

    @contains_hate.setter
    def contains_hate(self, contains_hate):
        """Sets the contains_hate of this NsfwAdvancedResult.

        True if the image contains hate, false otherwise  # noqa: E501

        :param contains_hate: The contains_hate of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._contains_hate = contains_hate

    @property
    def contains_potential_illegal_activity(self):
        """Gets the contains_potential_illegal_activity of this NsfwAdvancedResult.  # noqa: E501

        True if the image contains potentially illegal activity such as drugs, false otherwise  # noqa: E501

        :return: The contains_potential_illegal_activity of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._contains_potential_illegal_activity

    @contains_potential_illegal_activity.setter
    def contains_potential_illegal_activity(self, contains_potential_illegal_activity):
        """Sets the contains_potential_illegal_activity of this NsfwAdvancedResult.

        True if the image contains potentially illegal activity such as drugs, false otherwise  # noqa: E501

        :param contains_potential_illegal_activity: The contains_potential_illegal_activity of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._contains_potential_illegal_activity = contains_potential_illegal_activity

    @property
    def contains_medical_imagery(self):
        """Gets the contains_medical_imagery of this NsfwAdvancedResult.  # noqa: E501

        True if the image contains medical imagery, false otherwise  # noqa: E501

        :return: The contains_medical_imagery of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._contains_medical_imagery

    @contains_medical_imagery.setter
    def contains_medical_imagery(self, contains_medical_imagery):
        """Sets the contains_medical_imagery of this NsfwAdvancedResult.

        True if the image contains medical imagery, false otherwise  # noqa: E501

        :param contains_medical_imagery: The contains_medical_imagery of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._contains_medical_imagery = contains_medical_imagery

    @property
    def contains_profanity(self):
        """Gets the contains_profanity of this NsfwAdvancedResult.  # noqa: E501

        True if the image contains profanity or obscenities, false otherwise  # noqa: E501

        :return: The contains_profanity of this NsfwAdvancedResult.  # noqa: E501
        :rtype: bool
        """
        return self._contains_profanity

    @contains_profanity.setter
    def contains_profanity(self, contains_profanity):
        """Sets the contains_profanity of this NsfwAdvancedResult.

        True if the image contains profanity or obscenities, false otherwise  # noqa: E501

        :param contains_profanity: The contains_profanity of this NsfwAdvancedResult.  # noqa: E501
        :type: bool
        """

        self._contains_profanity = contains_profanity

    @property
    def score(self):
        """Gets the score of this NsfwAdvancedResult.  # noqa: E501

        Score between 0.0 and 1.0.  Scores of 0.0-0.2 represent high probability safe content, while scores 0.8-1.0 represent high probability unsafe content.  Content between 0.2 and 0.8 is of increasing raciness.  # noqa: E501

        :return: The score of this NsfwAdvancedResult.  # noqa: E501
        :rtype: float
        """
        return self._score

    @score.setter
    def score(self, score):
        """Sets the score of this NsfwAdvancedResult.

        Score between 0.0 and 1.0.  Scores of 0.0-0.2 represent high probability safe content, while scores 0.8-1.0 represent high probability unsafe content.  Content between 0.2 and 0.8 is of increasing raciness.  # noqa: E501

        :param score: The score of this NsfwAdvancedResult.  # noqa: E501
        :type: float
        """

        self._score = score

    @property
    def classification_outcome(self):
        """Gets the classification_outcome of this NsfwAdvancedResult.  # noqa: E501

        Classification result into four categories: SafeContent_HighProbability, UnsafeContent_HighProbability, RacyContent, SafeContent_ModerateProbability  # noqa: E501

        :return: The classification_outcome of this NsfwAdvancedResult.  # noqa: E501
        :rtype: str
        """
        return self._classification_outcome

    @classification_outcome.setter
    def classification_outcome(self, classification_outcome):
        """Sets the classification_outcome of this NsfwAdvancedResult.

        Classification result into four categories: SafeContent_HighProbability, UnsafeContent_HighProbability, RacyContent, SafeContent_ModerateProbability  # noqa: E501

        :param classification_outcome: The classification_outcome of this NsfwAdvancedResult.  # noqa: E501
        :type: str
        """

        self._classification_outcome = classification_outcome

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value
        if issubclass(NsfwAdvancedResult, dict):
            for key, value in self.items():
                result[key] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, NsfwAdvancedResult):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
